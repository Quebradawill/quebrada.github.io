---
layout: post
title: 深度学习基础 - 哈尔滨工业大学 - 刘远超
date: 2020-02-17
categories: Deep-learning
tags: Deeplearning
status: publish
type: post
published: true
author: Quebradawill
---

## 第一讲：深度学习概述

### 1.1 深度学习的引出

### 1.2 数据集及其拆分

1、类别标签的 ground truth 与 gold standard：

- ground truth：可翻译为地面实况等。在机器学习领域一般用于表示真实值、 标准答案等，表示通过直接观察收集到的真实结果。<br>
- gold standard：可翻译为金标准。医学上一般指诊断疾病公认的最可靠的方法。<br>
- 在机器学习领域，更倾向于使用“ground truth” 。 而如果用 gold standard 这个词，则表示其可以很好地代表 ground truth。

2、训练集（training set）、测试集（testing set）和验证集（validation set）：

- 训练集用来训练模型，即被用来学习得到系统的参数取值。<br>
- 测试集用于最终报告模型的评价结果，因此在训练阶段测试集中的样本应该是 unseen 的。<br>
- 有时对训练集做进一步划分为训练集和验证集。验证集与测试集类似，也是用于评估模型的性能。**区别**是验证集主要用于模型选择和调整超参数，因而一般不用于报告最终结果。

3、网格搜索调超参数

超参数是指在学习过程之前需要设置其值的一些变量。

网格搜索：

- 假设模型有两个超参数：$A$ 和 $B$。$A$ 的可能取值为 $\{ a1, a2, a3\}$，$B$ 的可能取值为连续的，如在区间 $[0, 1]$，由于 $B$ 值连续，通常对其离散化，如变为 $\{ 0, 0.25, 0.5, 0.75, 1\}$；<br>
- 如果使用网格搜索，就是尝试各种可能的 $(A,B)$ 值对，找到能使模型取得最高性能的 $(A,B)$ 值对。

网格搜索与 K 折交叉验证结合调整超参数的具体步骤：

- 确定评价指标；<br>
- 对于超参数取值的每种组合，在训练集上使用交叉验证的方法求得其 K 次评价的性能均值；<br>
- 最后，比较哪种超参数取值组合的性能最好，从而得到最优超参数的取值组合。

### 1.3 分类及其性能度量

### 1.4 回归问题及其性能评价

1、常用的评价回归问题的方法

- 平均绝对误差 MAE（mean absolute error）；<br>
- 均方误差 MSE（mean squared error）及均方根差 RMSE；<br>
- Log loss，或称交叉熵 loss（cross-entropy loss）；<br>
- R方值，确定系数（r2 score）。

### 1.5 一致性的评价方法

1、一致性评价：是指对两个或多个相关的变量进行分析，从而衡量其相关性的密切程度。

2、皮尔森相关系数（Pearson coefficient）法

应用背景：

- 用来衡量两个用户之间兴趣的一致性；<br>
- 用来衡量预测值与真实值之间的相关性；<br>
- 既适用于离散的、也适用于连续变量的相关分析。

计算公式：


$$
\rho_{X,Y} = \frac{\textrm{cov}(X,Y)}{\sigma_X \sigma_Y} = \frac{E[(X - \mu_X)(Y - \mu_Y)]}{\sigma_X \sigma_Y}
$$


皮尔森相关系数的取值区间为 $[-1, 1]$。

3、Cohen‘s kappa 相关系数

也可用于衡量两个评价者之间的一致性。其特点在于：

- 与 Pearson 相关系数的区别：Cohen‘s kappa 相关系数通常用于**离散**分类的一致性评价；<br>
- 其通常被认为比两人之间的简单一致百分比**更强壮**，因为 Cohen‘s kappa考虑到了二人之间的随机一致的可能性；<br>
- 如果评价者多于 2 人时，可以考虑使用 Fleiss' kappa。

4、Fleiss' kappa

## 第二讲：特征工程概述



## 第三讲：回归问题及正则化



## 第四讲：信息熵及梯度计算



## 第五讲：循环神经网络及其变体



## 第六讲：卷积神经网络



## 第七讲：递归神经网络



## 第八讲：生成式神经网络